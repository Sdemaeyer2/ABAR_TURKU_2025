---
title: "Day 1: the prior, the likelihood, and the posterior"
format: html
---

## Outline

In the first part, we will introduce the basic rationale behind Bayesian statistics. We start by explaining the three key components of a Bayesian model: the **prior**, the **likelihood**, and the **posterior**. 

Then, we switch to the estimation of parameters by first introducing the basic idea of grid approximation and then outlining the basic idea of MCMC sampling.

At the end of the session we introduce `brms` and learn how to estimate a simple regression model with `brms` and just use the `summary()` and `plot()` functions to get insight in the model results.

## Materials

### Slides

The htlm-version of the slides for this first part can be found <a href="Presentations/Part1/Slides_Part1.html" target="blank">here</a>

### Data

For this first part, we use a straightforward dataset on predicting racetimes for a marathon. The data can be downloaded <a href="Data/MarathonData.RData" target="blank"> here </a> (right-click to save as). 

## References and resources

Data comes from <a href="https://www.kaggle.com/datasets/girardi69/marathon-time-predictions?resource=download" target="blank">Kaggle</a>

Paul Bürkner’s presentation available on YouTube:<a href="https://www.youtube.com/watch?v=FRs1iribZME" target="blank"> click here</a>

Interactive tool demonstrating MCMC sampling: 
<a href="https://chi-feng.github.io/mcmc-demo/app.html#HamiltonianMC,standard" target="blank"> click here </a>

`brms` homepage: <a href="https://paul-buerkner.github.io/brms/" target="blank"> click here </a>
